# The Monitoring Pipeline

The Monitoring pipeline monitors the performance of a hosted model and the input data it receives. It runs a series of tests and generates several reports using the data captured by the model and a reference dataset.

![Monitoring pipeline](.guide/monitoring-pipeline/images/monitoring.png)

To test the Monitoring pipeline, we'll [generate fake traffic](.guide/monitoring-pipeline/generating-fake-traffic.md) to the hosted model. The model will store the input data and the predictions it generates. We will then [generate ground truth labels](.guide/monitoring-pipeline/generating-fake-labels.md) for that data to evaluate the model's performance.

To run the pipeline, you can use the following command:

```shell
uv run -- python pipelines/monitoring.py \
    --environment conda run
```

You can also use the `just` command with the `monitor` recipe:

```shell
just monitor
```

The pipeline will load the reference and production datasets and generate a series of reports to evaluate the quality of the data and the model's performance. By default, the pipeline uses the `backend.Local` implementation to load the production data from a SQLite database. You can change the [backend implementation](pipelines/inference/backend.py) by specifying the `--backend` property:

```shell
uv run -- python pipelines/monitoring.py \
    --environment conda run \
    --backend backend.Local
```

To provide configuration settings to a specific backend implementation, you can use the `--config` parameter to supply a JSON configuration file to the pipeline. The [`config/local.json`](config/local.json) file is an example configuration file for the [`backend.Local`](pipelines/inference/backend.py) backend. You can use this file as follows:

```shell
uv run -- python pipelines/monitoring.py \
    --environment conda \
    --config config config/local.json run \
    --backend backend.Local
```

By default, the pipeline will load the latest 500 samples stored in the backend and use them to generate the reports. You can change the number of samples to load by using the `--limit` parameter when running the pipeline:

```shell
uv run -- python pipelines/monitoring.py \
    --environment conda run \
    --limit 1000
```

To display the supported parameters of the Monitoring pipeline, run the following command:

```shell
uv run -- python pipelines/monitoring.py \
    --environment conda run --help
```

After the pipeline finishes running, you can visualize the generated reports using Metaflow's built-in viewer:

```shell
uv run -- python pipelines/monitoring.py \
    --environment conda card server --port 8334
```

You can also use the `just` command with the `monitor-viewer` recipe:

```shell
just monitor-viewer
```

After the card server is running, open your browser and navigate to [localhost:8334](http://localhost:8334). Every time you run the Monitoring pipeline, the viewer will automatically update to show the every report generated by the pipeline.